{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3134740-6265-484a-88a9-a4b044c1506b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hsa_dRNA_HeLa_NoArs_polyA_5P_1_24n_adaptive/adaptive_test'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD_NAME = 'rad5cds_local.max.ds2to11_adaptive_wd0.1.pth'\n",
    "LOAD_NAME = 'rad5cds_local.max.ds2to11_adaptive_wd0.01_25n.pth'\n",
    "# LOAD_NAME = 'rad5cds_local.max.ds2to11_adaptive_wd0.1_accum2_steps4500_51n.pth'\n",
    "\n",
    "\n",
    "# LOAD_NAME = 'rad5cds_local.max_adaptive.pth'\n",
    "\n",
    "\n",
    "# reads_dataset_name = \"hsa.dRNASeq.HeLa.polyA.REL5.long.1\"\n",
    "# reads_dataset_name = \"hsa.dRNASeq.HeLa.polyA.REL5.long.2\"\n",
    "reads_dataset_name = \"hsa_dRNA_HeLa_NoArs_polyA_5P_1\"\n",
    "# reads_dataset_name = \"ds1ds2\"\n",
    "\n",
    "# reads_dataset_preprocessing = 'cds_local.max2/adaptive'\n",
    "# reads_dataset_preprocessing = 'cds_local.max/adaptive'\n",
    "reads_dataset_preprocessing = 'adaptive/adaptive'\n",
    "# reads_dataset_preprocessing = 'original'\n",
    "\n",
    "dataset_save_name = reads_dataset_name\n",
    "\n",
    "SEQ_LENGTH = 24\n",
    "if SEQ_LENGTH != 200:\n",
    "    dataset_save_name = dataset_save_name + \"_\" + str(SEQ_LENGTH) + 'n' + \"_\" \n",
    "\n",
    "log_number = 9\n",
    "\n",
    "LOG_OUTPUT_LOCATION = \"results_logs/{}_trained_{}_tested_{}.txt\".format(LOAD_NAME, reads_dataset_preprocessing.replace('/', '.'), log_number)\n",
    "\n",
    "dataset_save_name = dataset_save_name + reads_dataset_preprocessing + \"_test\"\n",
    "dataset_save_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c01c9107-1c88-4892-ae3d-d27bd904a0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/my-conda-envs/decay3/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import comet_ml\n",
    "from torch import cuda\n",
    "cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f58977-7639-4acb-89c0-94f59dac6be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 08:55:45.856854: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from raw_to_input import *\n",
    "from raw_to_input import reformat, parse_data, parse_neg\n",
    "\n",
    "\n",
    "def load_data(upstream5p, downstream3p, within, rbpfile, negfile, rep, onehot):\n",
    "    \"\"\"Parses and processes data from input FASTA and BED files and returns it in train and testing portions.\n",
    "    @param upstream5p\n",
    "    \"\"\"\n",
    "    # I do not use the RBPs now, but leaving the code here for later\n",
    "    rbp_dict = get_rbp_dict(rbpfile)\n",
    "\n",
    "    x, rbps, y = [], [], []\n",
    "    # Iterate through files and append sequences and corresponding labels and region information to above data arrays\n",
    "    parse_data(upstream5p, x, y, rbps, rbp_dict, 5, rep, onehot, length=SEQ_LENGTH)\n",
    "    print(len(y), ' processed upstream5p; ', 'currect label balance: ', y.count(1), ' ones, ', y.count(0), ' zeros')\n",
    "    parse_data(downstream3p, x, y, rbps, rbp_dict, 3, rep, onehot, length=SEQ_LENGTH)\n",
    "    print(len(y), ' processed downstream3p; ', 'currect label balance: ', y.count(1), ' ones, ', y.count(0), ' zeros')\n",
    "    parse_data(within, x, y, rbps, rbp_dict, \"w\", rep, onehot, length=SEQ_LENGTH)\n",
    "    print(len(y), ' processed within; ', 'currect label balance: ', y.count(1), ' ones, ', y.count(0), ' zeros')\n",
    "\n",
    "    x_neg, rbps_neg, y_neg = [], [], []\n",
    "    \n",
    "    # generate negatives\n",
    "    # in each cycle there we add 1 random positive\n",
    "    while y.count(1) > y_neg.count(0):\n",
    "        parse_neg(negfile, x_neg, y_neg, rbps_neg, rbp_dict, rep, onehot, length=SEQ_LENGTH)\n",
    "        print(len(y_neg), ' processed negfile; ', 'current label balance: ', y.count(1), ' ones, ', y_neg.count(0), ' zeros')\n",
    "    \n",
    "    # combine the positives with the generated negatives\n",
    "    x.extend(x_neg[:len(y)])    \n",
    "    rbps.extend(rbps_neg[:len(y)])  \n",
    "    y.extend(y_neg[:len(y)])\n",
    "    print(len(y), ' total; ', 'label balance: ', y.count(1), ' ones, ', y.count(0), ' zeros')\n",
    "    \n",
    "    return x, rbps, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96aafaab-a22e-452d-85f9-4125cc3eb55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = '/home/jovyan'\n",
    "pos_5p_train = home_path + '/decay/decay/get_fasta/results/{}/{}/decay_seqs_fasta/upstream-5P-end-transcripts_fasta_train.fa'.format(reads_dataset_name, reads_dataset_preprocessing)\n",
    "pos_5p_test = home_path + '/decay/decay/get_fasta/results/{}/{}/decay_seqs_fasta/upstream-5P-end-transcripts_fasta_test.fa'.format(reads_dataset_name, reads_dataset_preprocessing)\n",
    "\n",
    "pos_3p_train = home_path + '/decay/decay/get_fasta/results/{}/{}/decay_seqs_fasta/downstream-3P-end-transcripts_fasta_train.fa'.format(reads_dataset_name, reads_dataset_preprocessing)\n",
    "pos_3p_test = home_path + '/decay/decay/get_fasta/results/{}/{}/decay_seqs_fasta/downstream-3P-end-transcripts_fasta_test.fa'.format(reads_dataset_name, reads_dataset_preprocessing)\n",
    "\n",
    "within_train = home_path + '/decay/decay/get_fasta/results/{}/{}/decay_seqs_fasta/within_transcripts_fasta_train.fa'.format(reads_dataset_name, reads_dataset_preprocessing)\n",
    "within_test = home_path + '/decay/decay/get_fasta/results/{}/{}/decay_seqs_fasta/within_transcripts_fasta_test.fa'.format(reads_dataset_name, reads_dataset_preprocessing)\n",
    "\n",
    "neg_file = home_path + '/decay/decay/data/hg38/transcripts.fa'\n",
    "\n",
    "rbp_file = home_path + '/decay/decay/rbp_data/AATF.bed'\n",
    "\n",
    "rep = False # was True --- switch for soft-masked and hard-masked nucleotides \n",
    "onehot = False # Return nucleotide characters or one-hot vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00ee5b04-0772-414a-a274-871f67f27ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/decay/decay/get_fasta/results/hsa_dRNA_HeLa_NoArs_polyA_5P_1/adaptive/adaptive/decay_seqs_fasta/upstream-5P-end-transcripts_fasta_test.fa'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_5p_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcdf8ab-1472-4cd3-9870-8fa4114ecdff",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc7e132-fd5a-4ecc-99f3-32d026abe1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(dataset_save_name):\n",
    "    # Load test data\n",
    "    x_test, rbps_test, y_test = load_data(\n",
    "        pos_5p_test, pos_3p_test, within_test, \n",
    "        rbp_file, neg_file, rep, onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8be8b33-ca55-41d8-b680-055317bcb83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dataset_save_name):\n",
    "    if onehot:\n",
    "        n_seqlength, n_features = x_test[0].shape[0], x_test[0].shape[1]\n",
    "        n_seqlength, n_features\n",
    "    n_seqlength, n_features = np.shape(x_test)[0], np.shape(x_test)[1]\n",
    "    n_seqlength, n_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7dce34-f09d-4523-92f9-2970c8efda29",
   "metadata": {},
   "source": [
    "# Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c26b31-11f0-491d-83ef-31d0cfe4728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Parameters\n",
    "\n",
    "MODEL_NAME = \"simecek/DNADebertaK6c\"\n",
    "TOKENIZER_NAME = \"armheb/DNA_bert_6\"\n",
    "K = 6\n",
    "STRIDE = 1\n",
    "\n",
    "SEED=42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76e9133e-b670-4c4e-b920-59b9d54337e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fa7e64-43a5-4820-872e-bfbcc5264743",
   "metadata": {},
   "source": [
    "## Nucleotide masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f378d8f-d7f1-452c-9315-10c1685550b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "if not os.path.exists(dataset_save_name):\n",
    "\n",
    "    hard_nucleotide_masking = False\n",
    "    if not hard_nucleotide_masking:\n",
    "    #     hack to unmask nucleotides\n",
    "        x_test = np.char.upper(x_test)\n",
    "    else:\n",
    "        # no action needed, the tokenizer will map lower case chars to UNK tokens\n",
    "        pass\n",
    "\n",
    "    def kmers_strideK(s, k=K):\n",
    "        return [s[i:i + k] for i in range(0, len(s), k) if i + k <= len(s)]\n",
    "\n",
    "    def kmers_stride1(s, k=K):\n",
    "        return [s[i:i + k] for i in range(0, len(s)-k+1)]\n",
    "\n",
    "    if (STRIDE == 1):\n",
    "        kmers = kmers_stride1\n",
    "    else:\n",
    "        kmers = kmers_strideK\n",
    "\n",
    "    # function used for the actual tokenization\n",
    "    if(K is not None):\n",
    "        def tok_func(x): return tokenizer(\" \".join(kmers(x[\"seq\"])), truncation=True)\n",
    "    else:\n",
    "        def tok_func(x): return tokenizer(x[\"seq\"], truncation=True)\n",
    "\n",
    "\n",
    "    tmp_dict_test = {}\n",
    "    # TEST\n",
    "    for index, (x, y) in enumerate(zip(x_test, y_test)):\n",
    "        tmp_dict_test[f\"{index}\"] = (\"test\", y, x)\n",
    "\n",
    "    df_test = pd.DataFrame.from_dict(tmp_dict_test).T.rename(columns = {0: \"dset\", 1: \"cat\", 2: \"seq\"})\n",
    "\n",
    "    df_test['seq'] = [''.join(map(str, l)) for l in df_test['seq']]\n",
    "\n",
    "\n",
    "    ds_test = Dataset.from_pandas(df_test)\n",
    "\n",
    "    tok_ds_test = ds_test.map(tok_func, batched=False, remove_columns=['__index_level_0__', 'seq'])\n",
    "    tok_ds_test = tok_ds_test.rename_columns({'cat':'labels'})\n",
    "\n",
    "\n",
    "    dds = DatasetDict({\n",
    "        # 'train': [],\n",
    "        # 'valid': [],\n",
    "        'test': tok_ds_test\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fb3bf5-d34e-4c1f-a0b7-626026916bf6",
   "metadata": {},
   "source": [
    "### Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff3ceb36-e884-4253-b109-768059c5f69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: hsa_dRNA_HeLa_NoArs_polyA_5P_1_24n_adaptive/adaptive_test\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "if os.path.exists(dataset_save_name):\n",
    "    print(\"File exists:\", dataset_save_name)\n",
    "    dds = load_from_disk(dataset_save_name)\n",
    "else:\n",
    "    print(\"File not found:\", dataset_save_name)\n",
    "    dds.save_to_disk(dataset_save_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47d81569-9ee8-4528-96fb-570874e27139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "binary_metrics = evaluate.combine([\n",
    "    'accuracy',\n",
    "    'f1',\n",
    "    'recall',\n",
    "    'precision',\n",
    "    #Order of roc_auc matters for logging -> macro first, then weighted\n",
    "    evaluate.load('roc_auc', average='macro'),\n",
    "    evaluate.load('roc_auc', average='weighted'),\n",
    "    evaluate.load(\"Vlasta/pr_auc\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ef60c38-8851-4774-a408-ffb096e7837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import random, randrange\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "from datasets import load_metric\n",
    "\n",
    "\n",
    "def compute_metrics_binary(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    prediction_scores = torch.nn.functional.softmax(\n",
    "        torch.from_numpy(logits).double(), dim=-1).numpy() \n",
    "    # predictions = np.argmax(logits, axis=-1) #equivalent\n",
    "    predictions = np.argmax(prediction_scores, axis=-1)\n",
    "    return binary_metrics.compute(\n",
    "        predictions=predictions, \n",
    "        references=labels, \n",
    "        prediction_scores=prediction_scores[:,1] #taking only prediction percentage for the label 1\n",
    "    )\n",
    "    \n",
    "#TODO dataset multilabel metrics\n",
    "def compute_metrics_multi(eval_preds):\n",
    "    metric = load_metric(\"accuracy\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad75392f-ac46-4413-9138-eeff75976d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_labels=2\n",
    "compute_metrics = compute_metrics_binary if num_of_labels == 2 else compute_metrics_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8e0011e-22d6-4e0d-b01c-a75dbb99e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(LOAD_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b214cc3-a980-450d-938b-96bba8447256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3993/1436649.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6759899626660139}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming the 'model' variable contains the loaded PyTorch model\n",
    "# and the 'datasets' variable is an instance of the Dataset class, tokenized and ready for evaluation\n",
    "\n",
    "# Load the desired metric, e.g., accuracy\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "# Move the model to the appropriate device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Set the dataset format to PyTorch tensors\n",
    "eval_dataset = dds[\"test\"] \n",
    "eval_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Create a DataLoader for the evaluation dataset\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=16)\n",
    "\n",
    "predictions_logits = []\n",
    "# Evaluate the model on the dataset\n",
    "predictions, labels = [], []\n",
    "for batch in eval_dataloader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    batch_labels = batch['labels'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=batch_labels)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    predictions_logits.extend(logits.cpu().numpy())\n",
    "    batch_predictions = torch.argmax(logits, dim=-1)\n",
    "    predictions.extend(batch_predictions.cpu().numpy())\n",
    "    labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "# Compute the evaluation metric\n",
    "# compute_metrics_binary(eval_preds=(predictions, labels))\n",
    "eval_metric = metric.compute(predictions=predictions, references=labels)\n",
    "print(eval_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "956a6a3b-f53a-4133-9e62-aafb91f1d391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6759899626660139,\n",
       " 'f1': 0.6953619518931982,\n",
       " 'recall': 0.7395801456637493,\n",
       " 'precision': 0.6561329206711191,\n",
       " 'rocauc_0_roc_auc': 0.7418106689055893,\n",
       " 'rocauc_1_roc_auc': 0.7418106689055893,\n",
       " 'pr_auc': 0.7185300445909809}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = compute_metrics_binary((np.array(predictions_logits), np.array(labels)))\n",
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be41c0a7-9b23-4048-a587-146406abd827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "preds = np.argmax(predictions_logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2addb03c-4201-49c6-8525-3bf23759861b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16339 16339\n",
      "precision  0.6561329206711191\n",
      "recall  0.7395801456637493\n",
      "specificity  0.6123997796682783\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_test = metrics.confusion_matrix(labels, preds)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix_test.ravel()\n",
    "print(tp + fn, tn + fp)\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print('precision ', precision)\n",
    "print('recall ', recall)\n",
    "print('specificity ', specificity)\n",
    "\n",
    "confusion_matrix_test = confusion_matrix_test.tolist()\n",
    "confusion_matrix_test.append({'precision': precision, 'recall': recall, 'specificity': specificity})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdb6a54-0c53-4770-916e-05d305cd4dec",
   "metadata": {},
   "source": [
    "count of true negatives is C(0,0), false negatives is C(1,0), true positives is C(1,1) and false positives is C(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c916491-670f-4833-8784-211d4c71ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = [logs]\n",
    "logs.append({'confusion_matrix_test' : confusion_matrix_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20655475-6015-4970-aad9-a4c29c9e76dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.6759899626660139,\n",
       "  'f1': 0.6953619518931982,\n",
       "  'recall': 0.7395801456637493,\n",
       "  'precision': 0.6561329206711191,\n",
       "  'rocauc_0_roc_auc': 0.7418106689055893,\n",
       "  'rocauc_1_roc_auc': 0.7418106689055893,\n",
       "  'pr_auc': 0.7185300445909809},\n",
       " {'confusion_matrix_test': [[10006, 6333],\n",
       "   [4255, 12084],\n",
       "   {'precision': 0.6561329206711191,\n",
       "    'recall': 0.7395801456637493,\n",
       "    'specificity': 0.6123997796682783}]}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b69eeeff-4114-4dec-8da2-50938d502255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(LOG_OUTPUT_LOCATION, 'w+') as f:\n",
    "    f.write(json.dumps(logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01ce2ecb-2938-4270-b3dd-beedf206586e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results_logs/rad5cds_local.max.ds2to11_adaptive_wd0.01_25n.pth_trained_adaptive.adaptive_tested_9.txt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOG_OUTPUT_LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47037b03-65f7-4c32-b776-4373afdd7db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decay3]",
   "language": "python",
   "name": "conda-env-decay3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
